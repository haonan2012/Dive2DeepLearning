{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhd9zHRctu3CJpFAgFNkpw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haonan2012/Dive2DeepLearning/blob/master/1_LinearRegression_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilities"
      ],
      "metadata": {
        "id": "QuOEDAYMOGpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "\n",
        "def add_to_class(Class):\n",
        "  \"\"\"Register functions as methods in created class.\"\"\"\n",
        "  def wrapper(obj):\n",
        "    setattr(Class, obj.__name__, obj)\n",
        "  return wrapper\n",
        "\n",
        "\n",
        "class HyperParameters:\n",
        "  \"\"\"The base class of hyperparameters.\"\"\"\n",
        "  def save_hyperparameters(self, ignore=[]):\n",
        "    \"\"\"Save function arguments into class attributes.\"\"\"\n",
        "    frame = inspect.currentframe().f_back\n",
        "    _, _, _, local_vars = inspect.getargvalues(frame)\n",
        "    self.hparams = {k:v for k, v in local_vars.items()\n",
        "            if k not in set(ignore+['self']) and not k.startswith('_')}\n",
        "    for k, v in self.hparams.items():\n",
        "      setattr(self, k, v)\n",
        "\n",
        "\n",
        "from matplotlib_inline import backend_inline\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython import display\n",
        "import collections\n",
        "\n",
        "def use_svg_display():\n",
        "    \"\"\"Use the svg format to display a plot in Jupyter.\"\"\"\n",
        "    backend_inline.set_matplotlib_formats('svg')\n",
        "\n",
        "class ProgressBoard(HyperParameters):\n",
        "  \"\"\"The board that plots data points in animation.\"\"\"\n",
        "  def __init__(self, xlabel=None, ylabel=None, xlim=None,\n",
        "        ylim=None, xscale='linear', yscale='linear',\n",
        "        ls=['-', '--', '-.', ':'], colors=['C0', 'C1', 'C2', 'C3'],\n",
        "        fig=None, axes=None, figsize=(3.5, 2.5), display=True):\n",
        "    self.save_hyperparameters()\n",
        "  def draw(self, x, y, label, every_n=1):\n",
        "    Point = collections.namedtuple('Point', ['x', 'y'])\n",
        "    if not hasattr(self, 'raw_points'):\n",
        "      self.raw_points = collections.OrderedDict()\n",
        "      self.data = collections.OrderedDict()\n",
        "    if label not in self.raw_points:\n",
        "      self.raw_points[label] = []\n",
        "      self.data[label] = []\n",
        "    points = self.raw_points[label]\n",
        "    line = self.data[label]\n",
        "    points.append(Point(x, y))\n",
        "    if len(points) != every_n:\n",
        "      return\n",
        "    mean = lambda x: sum(x) / len(x)\n",
        "    line.append(Point(mean([p.x for p in points]),\n",
        "            mean([p.y for p in points])))\n",
        "    points.clear()\n",
        "    if not self.display:\n",
        "      return\n",
        "    use_svg_display()\n",
        "    if self.fig is None:\n",
        "      self.fig = plt.figure(figsize=self.figsize)\n",
        "    plt_lines, labels = [], []\n",
        "    for (k, v), ls, color in zip(self.data.items(), self.ls, self.colors):\n",
        "      plt_lines.append(plt.plot([p.x for p in v], [p.y for p in v],\n",
        "                  linestyle=ls, color=color)[0])\n",
        "      labels.append(k)\n",
        "    axes = self.axes if self.axes else plt.gca()\n",
        "    if self.xlim: axes.set_xlim(self.xlim)\n",
        "    if self.ylim: axes.set_ylim(self.ylim)\n",
        "    if not self.xlabel: self.xlabel = self.x\n",
        "    axes.set_xlabel(self.xlabel)\n",
        "    axes.set_ylabel(self.ylabel)\n",
        "    axes.set_xscale(self.xscale)\n",
        "    axes.set_yscale(self.yscale)\n",
        "    axes.legend(plt_lines, labels)\n",
        "    display.display(self.fig)\n",
        "    display.clear_output(wait=True)"
      ],
      "metadata": {
        "id": "koda_kySW6FU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "JCm82JZbw-Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataModule(HyperParameters):\n",
        "    \"\"\"The base class of data.\"\"\"\n",
        "    def __init__(self, root='../data', num_workers=4):\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def get_dataloader(self, train):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self.get_dataloader(train=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.get_dataloader(train=False)"
      ],
      "metadata": {
        "id": "xnXiDzs0DwjI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "class SyntheticRegressionData(DataModule):\n",
        "    \"\"\"Synthetic data for linear regression.\"\"\"\n",
        "    def __init__(self, w, b, noise=0.01, num_train=1000, num_val=1000,\n",
        "                 batch_size=32):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        n = num_train + num_val\n",
        "        self.X = torch.randn(n, len(w))\n",
        "        noise = torch.randn(n, 1) * noise\n",
        "        self.y = torch.matmul(self.X, w.reshape((-1, 1))) + b + noise\n",
        "    def get_dataloader(self, train):\n",
        "        if train:\n",
        "            indices = list(range(0, self.num_train))\n",
        "            # The examples are read in random order\n",
        "            random.shuffle(indices)\n",
        "        else:\n",
        "            indices = list(range(self.num_train, self.num_train+self.num_val))\n",
        "        for i in range(0, len(indices), self.batch_size):\n",
        "            batch_indices = torch.tensor(indices[i: i+self.batch_size])\n",
        "            yield self.X[batch_indices], self.y[batch_indices]"
      ],
      "metadata": {
        "id": "OswwwNdhD2LH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "class SyntheticRegressionData(DataModule):\n",
        "    \"\"\"Synthetic data for linear regression.\"\"\"\n",
        "    def __init__(self, w, b, noise=0.01, num_train=1000, num_val=1000,\n",
        "                 batch_size=32):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        n = num_train + num_val\n",
        "        self.X = torch.randn(n, len(w))\n",
        "        noise = torch.randn(n, 1) * noise\n",
        "        self.y = torch.matmul(self.X, w.reshape((-1, 1))) + b + noise\n",
        "\n",
        "    def get_tensorloader(self, tensors, train, indices=slice(0, None)):\n",
        "        tensors = tuple(a[indices] for a in tensors)\n",
        "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
        "        return torch.utils.data.DataLoader(dataset, self.batch_size, shuffle=train)\n",
        "\n",
        "    def get_dataloader(self, train):\n",
        "        i = slice(0, self.num_train) if train else slice(self.num_train, None)\n",
        "        return self.get_tensorloader((self.X, self.y), train, i)"
      ],
      "metadata": {
        "id": "q8qzlXbTuihB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = SyntheticRegressionData(w=torch.tensor([2.5,3.3]), b=5, num_train=5, num_val=2)\n",
        "train = data.train_dataloader()"
      ],
      "metadata": {
        "id": "i0Z07JChIWF9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.dataset.tensors\n"
      ],
      "metadata": {
        "id": "HzW0jdIyJEbQ",
        "outputId": "87563727-81d5-4348-ee1c-1569436b43b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.1556,  0.2272],\n",
              "         [ 0.9534, -0.8045],\n",
              "         [-0.4354,  2.3926],\n",
              "         [-0.0079,  1.6466],\n",
              "         [-1.9456,  0.3188]]),\n",
              " tensor([[ 8.6363],\n",
              "         [ 4.7310],\n",
              "         [11.8053],\n",
              "         [10.4068],\n",
              "         [ 1.1842]]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class Module(nn.Module, HyperParameters):\n",
        "    \"\"\"The base class of models.\"\"\"\n",
        "    def __init__(self, plot_train_per_epoch=2, plot_valid_per_epoch=1):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.board = ProgressBoard()\n",
        "\n",
        "    def loss(self, y_hat, y):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, X):\n",
        "        assert hasattr(self, 'net'), 'Neural network is defined'\n",
        "        return self.net(X)\n",
        "\n",
        "    def plot(self, key, value, train):\n",
        "        \"\"\"Plot a point in animation.\"\"\"\n",
        "        assert hasattr(self, 'trainer'), 'Trainer is not inited'\n",
        "        self.board.xlabel = 'epoch'\n",
        "        if train:\n",
        "            x = self.trainer.train_batch_idx / \\\n",
        "                self.trainer.num_train_batches\n",
        "            n = self.trainer.num_train_batches / \\\n",
        "                self.plot_train_per_epoch\n",
        "        else:\n",
        "            x = self.trainer.epoch + 1\n",
        "            n = self.trainer.num_val_batches / \\\n",
        "                self.plot_valid_per_epoch\n",
        "        self.board.draw(x, value.to(d2l.cpu()).detach().numpy(),\n",
        "                        ('train_' if train else 'val_') + key,\n",
        "                        every_n=int(n))\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
        "        self.plot('loss', l, train=True)\n",
        "        return l\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
        "        self.plot('loss', l, train=False)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        raise NotImplementedError"
      ],
      "metadata": {
        "id": "vwt9G_XbxfmF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}